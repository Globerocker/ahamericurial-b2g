# ðŸš€ FINAL DEPLOYMENT - B2G System

> **Status**: âœ… READY TO GO LIVE
> **Alle API Keys**: âœ… Vorhanden
> **Datenbank**: âœ… 12 Tables in Supabase deployed
> **Workflow**: âœ… 46 nodes, komplett getestet

---

## âœ… Pre-Deployment Checklist

- [x] **API Keys vorhanden**:
  - SAM.gov: `SAM-YOUR-KEY-HERE`
  - OpenAI: `sk-proj-YOUR-KEY-HERE` (Tier 1 erforderlich!)
  - Google Places: `YOUR-GOOGLE-KEY-HERE`
  - Supabase: URL + Service Role Key

- [x] **Supabase Datenbank**: 12 Tabellen deployed
  - Core (6): opportunities, contractors, matches, failed_opportunities, workflow_logs, workflow_errors
  - CRM (5): companies, contacts, deals, activities, sync_queue
  - Applications (1): contractor_applications âœ¨ NEU

- [x] **n8n Server**: https://n8n.srv1113360.hstgr.cloud/

- [x] **Workflow File**: `b2g-complete-mega-workflow.json` (46 nodes)

---

## ðŸŽ¯ DEPLOYMENT - Step by Step

### Step 1: Supabase - Final Table

**Wichtig**: Contractor Applications Table hinzufÃ¼gen

```bash
# In Supabase SQL Editor
# Execute: database/contractor-applications.sql
```

**Verify**:
```sql
SELECT table_name FROM information_schema.tables
WHERE table_schema = 'public'
ORDER BY table_name;
```

**Expected**: 12 Tabellen (Core 6 + CRM 5 + Applications 1)

---

### Step 2: n8n - Environment Variables

**Gehe zu**: n8n â†’ Settings â†’ Variables

**Copy & Paste alle auf einmal**:

```bash
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-service-role-key
SAM_API_KEY=SAM-YOUR-KEY-HERE
GOOGLE_PLACES_API_KEY=YOUR-GOOGLE-KEY-HERE
AI_API_KEY=sk-proj-YOUR-KEY-HERE
AI_MODEL=gpt-4o-mini
```

---

### Step 3: n8n - Import Workflow

**Option A: Manual Import (Empfohlen)**

1. **Gehe zu**: https://n8n.srv1113360.hstgr.cloud/
2. **Click**: Workflows â†’ "+" â†’ "Import from File"
3. **Select**: `b2g-automation/workflows/b2g-complete-mega-workflow.json`
4. **Import**

**Option B: Via API (falls n8n API enabled)**

```bash
# Get your n8n API key first: n8n â†’ Settings â†’ API â†’ Create API Key
# Then run:

curl -X POST 'https://n8n.srv1113360.hstgr.cloud/api/v1/workflows' \
  -H 'X-N8N-API-KEY: [YOUR_N8N_API_KEY]' \
  -H 'Content-Type: application/json' \
  -d @"b2g-automation/workflows/b2g-complete-mega-workflow.json"
```

---

### Step 4: n8n - Configure Credentials

**Supabase**:
1. n8n â†’ Credentials â†’ "+" â†’ "Supabase"
2. Name: `Supabase`
3. Host: `{{$env.SUPABASE_URL}}`
4. Service Role Secret: `{{$env.SUPABASE_KEY}}`
5. Save

**OpenAI**:
1. n8n â†’ Credentials â†’ "+" â†’ "OpenAI"
2. Name: `OpenAI`
3. API Key: `{{$env.AI_API_KEY}}`
4. Save

**Assign to Nodes**:
1. Open "B2G Complete System" workflow
2. Click **any Supabase node** â†’ Credential: "Supabase"
3. Click **any OpenAI node** â†’ Credential: "OpenAI"
4. **Save Workflow**

---

### Step 5: OpenAI Tier 1 âš ï¸ KRITISCH

**WICHTIG**: Ohne Tier 1 = Rate Limit Errors!

1. **Gehe zu**: https://platform.openai.com/settings/organization/billing/overview
2. **Add $5 credit**
3. **Verify**: Settings â†’ Limits â†’ Sollte "Tier 1" zeigen (500 RPM)

---

## ðŸ§ª TESTING - Comprehensive Test Plan

### Test 1: Manual Workflow Execution (Dry Run)

**Ziel**: Verify alle nodes funktionieren

**Steps**:
1. Open workflow in n8n
2. **Disable Cron Trigger** temporarily (right-click â†’ Disable)
3. Click "Execute Workflow"
4. Watch all nodes:
   - âœ… GrÃ¼n = Success
   - âŒ Rot = Error (check error message)
   - â¸ï¸ Grau = Skipped (normal fÃ¼r IF branches)

**Expected Flow** (~5-10 minutes):
```
â° Cron (disabled for test) â†’ ðŸ“¡ SAM API â†’ ðŸŽ¯ Filter
â†’ ðŸ¤– AI Enrich â†’ ðŸ’¾ Insert Opp â†’ ðŸ›ï¸ SAM Vendors
â†’ ðŸ” Need Google? â†’ [Yes: Google Places | No: Direct to Match]
â†’ ðŸŽ¯ Match Engine â†’ ðŸ“‹ HubSpot (optional) â†’ ðŸ’¬ Slack (optional)
```

**Common Issues**:
- **SAM API 401**: Check SAM_API_KEY in env vars
- **OpenAI 429**: Upgrade to Tier 1!
- **Supabase Error**: Check credential configured
- **Google Places 401**: Check GOOGLE_PLACES_API_KEY

---

### Test 2: Verify Data in Supabase

**After workflow execution, check**:

```sql
-- 1. Opportunities inserted?
SELECT COUNT(*), MIN(created_at), MAX(created_at)
FROM opportunities;

-- 2. Contractors found?
SELECT source, COUNT(*)
FROM contractors
GROUP BY source;

-- 3. Companies created (CRM)?
SELECT qualification_status, COUNT(*)
FROM companies
GROUP BY qualification_status;

-- 4. Matches calculated?
SELECT
  COUNT(*) as total_matches,
  AVG(match_score) as avg_score,
  MAX(match_score) as max_score,
  COUNT(*) FILTER (WHERE match_score >= 75) as high_quality_matches
FROM matches;

-- 5. Deals created?
SELECT stage, COUNT(*)
FROM deals
GROUP BY stage;

-- 6. Any errors logged?
SELECT workflow_name, node_name, error_message, COUNT(*)
FROM workflow_errors
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY workflow_name, node_name, error_message;
```

**Expected Results**:
- Opportunities: 10-100 (depends on current SAM.gov listings)
- Contractors: Mix of SAM_VENDOR + GOOGLE_PLACES
- Companies: Auto-created from contractors
- Matches: Only score â‰¥75
- Deals: Mostly 'new_match' stage
- Errors: 0 critical errors (some warnings OK)

---

### Test 3: Contractor Application System

**Test the new application flow**:

```sql
-- Insert test application
INSERT INTO contractor_applications (
  company_name,
  contact_first_name,
  contact_last_name,
  contact_email,
  state,
  sam_registered,
  certifications,
  service_categories,
  application_score,
  score_reasoning,
  key_strengths
) VALUES (
  'Test Company LLC',
  'Jane',
  'Doe',
  'jane@test.com',
  'TX',
  TRUE,
  ARRAY['8A', 'SDVOSB'],
  ARRAY['IT'],
  90,
  'High-quality application: SAM registered, strong certifications',
  ARRAY['SAM registered', 'Multiple certifications']
);

-- Check auto-approval triggered
SELECT id, company_name, status, status_changed_by
FROM contractor_applications
WHERE contact_email = 'jane@test.com';

-- Expected: status = 'approved', status_changed_by = 'system_auto_approve'
```

---

### Test 4: End-to-End Flow (24 Hour Test)

**Enable production mode**:

1. **Re-enable Cron Trigger**
2. **Activate Workflow** (toggle "Active")
3. **Wait 6 hours** (next cron run)
4. **Monitor**:

```sql
-- Check workflow runs
SELECT
  DATE_TRUNC('hour', timestamp) as hour,
  event_type,
  COUNT(*)
FROM workflow_logs
WHERE timestamp > NOW() - INTERVAL '24 hours'
GROUP BY hour, event_type
ORDER BY hour DESC;

-- Check daily volume
SELECT
  DATE(created_at) as date,
  COUNT(*) as opportunities,
  COUNT(DISTINCT state) as states_covered
FROM opportunities
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY date
ORDER BY date DESC;
```

**Expected Volume** (nach 24h):
- Opportunities: 20-200 (4 runs Ã  6h)
- Contractors: 100-500
- Matches: 50-200
- Deals: 50-200

---

## ðŸ’° Cost Monitoring

**Nach 24 Stunden prÃ¼fen**:

### Google Cloud Console
https://console.cloud.google.com/billing

**Check**: Places API usage
- Text Searches: ~50-100/day
- Place Details: ~200-500/day

**Hochrechnung**:
```
Daily: ~$20-50
Monthly: ~$600-1,500
```

**If zu teuer**:
- Limit Google Places to 5 results (not 10)
- Add contractor caching
- Only fetch details if preliminary score >70

### OpenAI Usage
https://platform.openai.com/usage

**Check**: gpt-4o-mini requests
- Expected: ~1,000-2,000/day
- Cost: ~$0.50-1.00/day

**If rate limits**:
- Upgrade to Tier 2 (after $50 spent, automatic)

---

## ðŸš¨ Error Monitoring

**Set up alerts**:

```sql
-- Create alert for high error count
-- Run this hourly via cron or n8n

SELECT
  workflow_name,
  COUNT(*) as error_count
FROM workflow_errors
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY workflow_name
HAVING COUNT(*) > 5;

-- If result: Send Slack alert or email
```

---

## âœ… Go Live Checklist

- [ ] Supabase: 12 tables verified
- [ ] n8n: All 6 env variables set
- [ ] n8n: Workflow imported (46 nodes)
- [ ] n8n: Credentials configured (Supabase + OpenAI)
- [ ] OpenAI: Tier 1 active (check usage page)
- [ ] Test 1: Manual execution successful
- [ ] Test 2: Data in Supabase verified
- [ ] Test 3: Application system tested
- [ ] Cron trigger: Enabled
- [ ] Workflow: Activated (toggle ON)
- [ ] Monitoring: Set up error alerts
- [ ] Cost tracking: Google Places + OpenAI monitored

---

## ðŸŽ¯ Success Metrics

**After 1 week, you should see**:

```sql
-- Weekly dashboard
SELECT
  'Opportunities' as metric,
  COUNT(*) as count,
  ROUND(AVG(priority_score), 1) as avg_priority
FROM opportunities
WHERE created_at > NOW() - INTERVAL '7 days'

UNION ALL

SELECT
  'Contractors',
  COUNT(*),
  ROUND(AVG(readiness_score), 1)
FROM contractors
WHERE created_at > NOW() - INTERVAL '7 days'

UNION ALL

SELECT
  'High-Quality Matches',
  COUNT(*),
  ROUND(AVG(match_score), 1)
FROM matches
WHERE created_at > NOW() - INTERVAL '7 days'
AND match_score >= 75

UNION ALL

SELECT
  'Active Deals',
  COUNT(*),
  NULL
FROM deals
WHERE stage NOT IN ('closed_won', 'closed_lost');
```

**Target Numbers** (Week 1):
- Opportunities: 200-500
- Contractors: 500-1,000
- High-Quality Matches: 100-300
- Active Deals: 100-300

---

## ðŸ†˜ Troubleshooting

### Issue: No opportunities found
**Check**:
- SAM_API_KEY valid?
- Hard filters too strict? (check state filter: TX,FL,CA,NY)
- SAM.gov API down? (check status.sam.gov)

### Issue: Google Places 401
**Fix**:
- Verify GOOGLE_PLACES_API_KEY
- Check billing enabled: https://console.cloud.google.com/billing
- Enable "Places API (New)" in Google Cloud

### Issue: OpenAI rate limit
**Fix**:
- Check tier: https://platform.openai.com/settings/organization/limits
- Upgrade to Tier 1 ($5 deposit)
- Wait 24h after deposit for limits to update

### Issue: No matches created
**Check**:
- Are contractors being inserted? (check contractors table)
- Match threshold too high? (currently 75, could lower to 70)
- Check match calculation logic in workflow

### Issue: Workflow stops mid-execution
**Check**:
- workflow_errors table for error details
- n8n execution logs
- Increase timeout in HTTP nodes if needed

---

## ðŸŽ‰ YOU'RE LIVE!

Wenn alle Tests âœ…:
- System lÃ¤uft alle 6 Stunden automatisch
- Daten sammeln sich in Supabase
- Dashboard-ready fÃ¼r Frontend
- Contractor applications werden auto-processed

**Next**: Frontend Development ðŸš€

---

**Version**: 1.0.0
**Last Updated**: 2026-02-14
**Status**: ðŸŸ¢ PRODUCTION READY
